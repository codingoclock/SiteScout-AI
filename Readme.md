# ğŸ” SiteScout AI â€” Website Intelligence with RAG

**An open-source, agentic Retrieval-Augmented Generation (RAG) framework for websites, powered by LlamaIndex.**

> Website Ingestion â€¢ Vector Search â€¢ Agentic Reasoning â€¢ Plug-and-Play LLMs

[![Python](https://img.shields.io/badge/Python-3.10%20|%203.11%20|%203.12-blue)](https://www.python.org/)
[![LlamaIndex](https://img.shields.io/badge/LlamaIndex-RAG-purple)](https://github.com/run-llama/llama_index)
[![OpenAI](https://img.shields.io/badge/OpenAI-GPT-black)](https://platform.openai.com/)
[![Ollama](https://img.shields.io/badge/Ollama-Local%20LLMs-orange)](https://ollama.com/)
[![ChromaDB](https://img.shields.io/badge/ChromaDB-VectorDB-green)](https://www.trychroma.com/)
[![Redis](https://img.shields.io/badge/Redis-Cache-red)](https://redis.io/)
[![MongoDB](https://img.shields.io/badge/MongoDB-NoSQL-brightgreen)](https://www.mongodb.com/)
[![Status](https://img.shields.io/badge/Status-Active--Development-brightblue)](#-quick-start)
[![License](https://img.shields.io/badge/License-MIT-green)](LICENSE)


---

## ğŸš¨ Python Version Requirement (Strict)

> **SiteScout AI runs ONLY on Python 3.10, 3.11, or 3.12**

âŒ Python â‰¤ 3.9 â†’ **Not supported**  
âŒ Python â‰¥ 3.13 â†’ **Not tested**

This constraint exists due to:
- LlamaIndex internal dependencies
- Async event-loop compatibility
- Vector store bindings

ğŸ‘‰ **If your Python version is outside this range, the project will not run.**

---

## ğŸš€ What Is SiteScout AI?

SiteScout AI converts websites into **intelligent, queryable knowledge bases** using Retrieval-Augmented Generation (RAG).

Instead of relying on static prompts, SiteScout:
- Parses website content into structured documents
- Generates vector embeddings
- Stores them in pluggable vector stores
- Uses **agent-based reasoning** to answer questions accurately

Think:
> *â€œChatGPT, but grounded strictly in my websiteâ€™s content.â€*

---

## âœ¨ Key Features

### ğŸ§© Modular Architecture
- Factory-pattern design
- Swap LLMs, storage backends, and indexes without refactoring
- Clean separation of concerns

### ğŸ§  Multiple LLM Providers
- **OpenAI** (GPT-3.5 / GPT-4)
- **Ollama** (local open-source models)
- Easy extension for future providers

### ğŸ—„ï¸ Flexible Storage Backends
- **ChromaDB** â€” vector embeddings
- **Redis** â€” document caching
- **MongoDB** â€” scalable document & index storage

### ğŸ“š Indexing Strategies
- Vector Store Index
- Summary Index
- Hybrid-ready design

### ğŸ¤– Agentic RAG Workflow
- Built on `llama-index` agents
- Multi-step reasoning
- Context-aware, grounded responses

---

## âš¡ Quick Start

### âœ… Prerequisites
- **Python 3.10 / 3.11 / 3.12**
- pip
- (Optional) Ollama for local LLMs

Verify Python version:
```bash
python --version
```
## ğŸ§¬ Installation
### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/codingoclock/ProsZ-Future-Prosthetics.git
cd ProsZ-Future-Prosthetics
```
### 2ï¸âƒ£ Install Dependencies
```bash 
pip install -r requirements.txt
```
## âš™ï¸ Configuration
#### SiteScout AI uses environment variables for LLMs and storage backends.
### ğŸ”‘ OpenAI
```bash
export OPENAI_API_KEY=your_openai_api_key
```
## ğŸ§  Ollama (Local LLMs)
``` bash
ollama serve
```
#### Ensure a model is available:
``` bashh
ollama pull mistral
```
## ğŸ—„ï¸ Redis
```bash
export STORE_HOST=localhost
export STORE_PORT=6379
```
## ğŸƒ MongoDB
``` bash
export URI=mongodb+srv://your_cluster_url
```
## â–¶ï¸ Running the RAG Agent
``` bash
from sitescoutai.agent.chat.manager import RAGManager
from sitescoutai.config import Config

config = Config()
agent = RAGManager(config)

response = agent.query("Hello, SiteScout!")
print(response)
```
## ğŸ“ Project Structure
```
sitescoutai/
â”œâ”€â”€ agent/
â”‚   â””â”€â”€ chat/
â”‚       â”œâ”€â”€ index.py       # Index creation & loading
â”‚       â”œâ”€â”€ llm.py         # OpenAI / Ollama wrappers
â”‚       â”œâ”€â”€ logger.py      # Logging configuration
â”‚       â”œâ”€â”€ manager.py     # Main RAG agent entry point
â”‚       â”œâ”€â”€ parsing.py     # Document parsing & chunking
â”‚       â””â”€â”€ storage.py     # Redis / MongoDB / Chroma backends
â”‚
â”œâ”€â”€ requirements.txt       # Python dependencies (3.10â€“3.12)
â”œâ”€â”€ setup.py
â””â”€â”€ README.md
```
## ğŸ”„ RAG Workflow
```bash
Website Content
      â†“
Document Parsing & Chunking
      â†“
Vector Embeddings
      â†“
Vector Store (ChromaDB)
      â†“
Agent Reasoning (LlamaIndex)
      â†“
Final Answer
```
## ğŸ¯ Use Cases
- Website chatbots
- Documentation assistants
- Product knowledge bases
- Customer support automation
- Developer portals
- Research & internal tools

## ğŸ› Troubleshooting
### âŒ Project fails to start
```bash
python --version
# Must be 3.10â€“3.12
```
### Reinstall dependencies:
``` bash
pip install -r requirements.txt --force-reinstall
```

### âŒ Ollama not responding
``` bash
ollama serve
```
### Check model availability:
```bash
ollama list
```
### âŒ Vector store issues
- Ensure ChromaDB directory permissions
- Restart Redis / MongoDB if enabled
- Clear cached indexes after schema changes

## ğŸ“ˆ Roadmap
- Website crawler integration
- Streaming responses
- Hybrid search (BM25 + vector)
- Multi-agent collaboration
- FastAPI API layer
- Authentication & access control
- Dashboard UI
- Docker & Kubernetes support
  
## ğŸ“„ License
- MIT License

## ğŸ‘¥ Contributing
### Contributions are welcome!
- Fork the repository
- Create a feature branch
- Submit a pull request
- Open issues for bugs or enhancements

### If this project helped you, consider giving it a â­ on GitHub.
 